{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_IDX = 0\n",
    "EOS_IDX = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2idx = {SOS_IDX: \"<SOS>\", EOS_IDX: \"<EOS>\", PAD_IDX: \"<PAD>\", UNK_IDX: \"<UNK>\"}\n",
    "        self.idx2word = [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]\n",
    "        self.sentence_list = []\n",
    "\n",
    "    def build_vocab(self, sentence_list):\n",
    "        self.idx2word += list(set([word for sentence in sentence_list for word in sentence.split()]))\n",
    "        self.word2idx = dict(zip(self.idx2word, range(0, len(self.idx2word))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicode2ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(language_name, path, data_type):\n",
    "    sentence_lines = open(path + '%s.tok.%s' % (data_type, language_name), encoding='utf-8').read().strip().split('\\n')\n",
    "    if language_name == \"en\":\n",
    "        sentence_lines = [normalize_string(cur_line) for cur_line in sentence_lines]\n",
    "    return sentence_lines\n",
    "\n",
    "path = \"./iwslt-zh-en/\"\n",
    "train_data = [read_data(\"zh\", path, \"train\"), read_data(\"en\", path, \"train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_language = Language(\"zh\")\n",
    "source_language.build_vocab(train_data[0])\n",
    "\n",
    "target_language = Language(\"en\")\n",
    "target_language.build_vocab(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.source_sentence = data[0]\n",
    "        self.target_sentence = data[1]\n",
    "        assert len(self.source_sentence) == len(self.target_sentence)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source_idx_list = [source_language.word2idx[cur_word] if cur_word in source_language.word2idx else UNK_IDX \n",
    "                           for cur_word in self.source_sentence[idx]]\n",
    "        target_idx_list = [target_language.word2idx[cur_word] if cur_word in target_language.word2idx else UNK_IDX \n",
    "                           for cur_word in self.source_sentence]\n",
    "        return ((source_idx_list, target_idx_list), (len(source_idx_list), len(target_idx_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def padding(batch):\n",
    "    padded_source_list = []\n",
    "    padded_target_list = []\n",
    "    source_length_list = []\n",
    "    target_length_list = []\n",
    "    \n",
    "    for data in batch:\n",
    "        \n",
    "        if data[1][0] > MAX_SENTENCE_LENGTH or data[1][1] > MAX_SENTENCE_LENGTH:\n",
    "            continue\n",
    "        source_length_list.append(data[1][0])\n",
    "        target_length_list.append(data[1][1])\n",
    "        \n",
    "        padded_source = np.pad(np.array(data[0][0]), pad_width = ((0, MAX_SENTENCE_LENGTH - data[1][0])), mode=\"constant\", constant_values=0)\n",
    "        padded_source_list.append(padded_source)\n",
    "        \n",
    "        padded_target = np.pad(np.array(data[0][1]), pad_width = ((0, MAX_SENTENCE_LENGTH - data[1][1])), mode=\"constant\", constant_values=0)\n",
    "        padded_target_list.append(padded_target)\n",
    "        \n",
    "    \n",
    "    return ((padded_source_list, padded_target_list), (source_length_list, target_length_list))\n",
    "\n",
    "\n",
    "train_dataset = LanguageDataset(train_data)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, collate_fn=padding, shuffle=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_num, vocab_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
    "        #self.embedding.load_state_dict({'weight': torch.from_numpy(pretrained_embeddings)})\n",
    "        self.GRU = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.randn(self.layer_num, self.batch_size, self.hidden_dim, device=device)\n",
    "    \n",
    "    def forward(self, sentence_list, sentence_length_list):\n",
    "        \n",
    "        #sentence_sort_idx, sentence_unsort_idx = batch_sort(sentence_length_list)\n",
    "        #sentence_list = sentence_list[sentence_sort_idx]\n",
    "        #sentence_length_list = sentence_length_list[sentence_sort_idx]\n",
    "        \n",
    "        embed = pack(self.embedding(sentence_list), sentence_length_list, batch_first=True)\n",
    "        batch_size, _ = sentence_list.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        packed_outputs, hidden = self.GRU(embed, hidden)\n",
    "        outputs, _ = unpack(packed_outputs, batch_first=True)\n",
    "        \n",
    "        return outputs, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder w/o Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_num, vocab_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.layer_num = layer_num\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.GRU = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sentence_list, sentence_length, hidden):\n",
    "        embed = F.relu(pack(self.embedding(sentence_list), sentence_length_list, batch_first=True))\n",
    "        packed_output, hidden = self.gru(output, hidden)\n",
    "        output, _ = unpack(packed_outputs, batch_first=True)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.randn(self.layer_num, self.batch_size, self.hidden_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def batch_sort(length_list):\n",
    "    sort_idx = np.argsort(-length_list)\n",
    "    unsort_idx = np.argsort(sort_idx)\n",
    "    return (sort_idx, unsort_idx)\n",
    "\n",
    "\n",
    "def train(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        # encode the source lanugage\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        # decode the context vector\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            # hint: print out decoder_output and decoder_attention\n",
    "            # TODO: add your code here to populate decoded_words and decoder_attentions\n",
    "            # TODO: do this in 2 ways discussed in class: greedy & beam_search\n",
    "            \n",
    "            # END TO DO\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    \"\"\"\n",
    "    Function that takes in attention and visualize the attention.\n",
    "    @param - input_sentence: string the represent a list of words from source language\n",
    "    @param - output_words: the gold translation in target language\n",
    "    @param - attentions: a numpy array\n",
    "    \"\"\"\n",
    "    # Set up figure with colorbar    \n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # TODO: Add your code here to visualize the attention\n",
    "    # look at documentation for imshow https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.matshow.html\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
