{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2idx = {PAD_IDX: \"<PAD>\", UNK_IDX: \"<UNK>\", SOS_IDX: \"<SOS>\", EOS_IDX: \"<EOS>\"}\n",
    "        self.idx2word = [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"]\n",
    "        self.sentence_list = []\n",
    "\n",
    "    def build_vocab(self, sentence_list):\n",
    "        self.idx2word += list(set([word for sentence in sentence_list for word in sentence]))\n",
    "        self.word2idx = dict(zip(self.idx2word, range(0, len(self.idx2word))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicode2ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(language_name, path, data_type):\n",
    "    file_lines = open(path + '%s.tok.%s' % (data_type, language_name), encoding='utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    if language_name == \"en\":\n",
    "        sentence_list = [[\"<SOS>\"]+[normalize_string(word) for word in line.split()]+[\"<EOS>\"] for line in file_lines]\n",
    "    else:\n",
    "        sentence_list = [[\"<SOS>\"]+[word for word in line.split()]+[\"<EOS>\"] for line in file_lines]\n",
    "    return sentence_list\n",
    "\n",
    "path = \"./iwslt-zh-en/\"\n",
    "train_data = [read_data(\"zh\", path, \"train\"), read_data(\"en\", path, \"train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_language = Language(\"zh\")\n",
    "source_language.build_vocab(train_data[0])\n",
    "\n",
    "target_language = Language(\"en\")\n",
    "target_language.build_vocab(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.source_sentence = dataset[0]\n",
    "        self.target_sentence = dataset[1]\n",
    "        assert len(self.source_sentence) == len(self.target_sentence)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_sentence)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "            \n",
    "        source_idx_list = [source_language.word2idx[cur_word] if cur_word in source_language.word2idx else UNK_IDX \n",
    "                           for cur_word in self.source_sentence[idx]]\n",
    "        target_idx_list = [target_language.word2idx[cur_word] if cur_word in target_language.word2idx else UNK_IDX \n",
    "                           for cur_word in self.target_sentence[idx]]\n",
    "        return ((source_idx_list, target_idx_list), (len(source_idx_list), len(target_idx_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def padding(batch):\n",
    "    padded_source_list = []\n",
    "    padded_target_list = []\n",
    "    source_length_list = []\n",
    "    target_length_list = []\n",
    "    \n",
    "    for data in batch:\n",
    "        \n",
    "        if data[1][0] > MAX_SENTENCE_LENGTH or data[1][1] > MAX_SENTENCE_LENGTH:\n",
    "            continue\n",
    "        source_length_list.append(data[1][0])\n",
    "        target_length_list.append(data[1][1])\n",
    "        \n",
    "        padded_source = np.pad(np.array(data[0][0]), pad_width = ((0, MAX_SENTENCE_LENGTH - data[1][0])), mode=\"constant\", constant_values=0)\n",
    "        padded_source_list.append(padded_source)\n",
    "        \n",
    "        padded_target = np.pad(np.array(data[0][1]), pad_width = ((0, MAX_SENTENCE_LENGTH - data[1][1])), mode=\"constant\", constant_values=0)\n",
    "        padded_target_list.append(padded_target)\n",
    "        \n",
    "    \n",
    "    return ((torch.from_numpy(np.array(padded_source_list)), torch.from_numpy(np.array(padded_target_list))), (torch.from_numpy(np.array(source_length_list)), torch.from_numpy(np.array(target_length_list))))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, collate_fn=padding, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_num, vocab_size, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
    "        #self.embedding.load_state_dict({'weight': torch.from_numpy(pretrained_embeddings)})\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.randn(self.layer_num, batch_size, self.hidden_dim, device=device).to(device)\n",
    "    \n",
    "    def forward(self, sentence_list, sentence_length_list):\n",
    "        \n",
    "        embed = pack(self.embedding(sentence_list), sentence_length_list, batch_first=True)\n",
    "        batch_size, _ = sentence_list.size()\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        packed_outputs, hidden = self.gru(embed, hidden)\n",
    "        outputs, _ = unpack(packed_outputs, batch_first=True)\n",
    "        \n",
    "        return outputs, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sort(src_sentence_list, src_length_list, tgt_sentence_list):\n",
    "    sort_idx = np.argsort(-src_length_list)\n",
    "    return [src_sentence_list[sort_idx], src_length_list[sort_idx], tgt_sentence_list[sort_idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder w/o attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, decoder_out_dim, layer_num, vocab_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dim, decoder_out_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embed = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embed, hidden)\n",
    "        output = self.softmax(self.fc(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.randn(self.layer_num, batch_size, self.hidden_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded, attn_applied), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUM = 15\n",
    "log_step = 100\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (sentence_pair, length_pair)) in train_loader:\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        src_sentence_list, src_length_list, tgt_sentence_list = batch_sort(sentence_pair[0], length_pair[0], sentence_pair[1])\n",
    "        encoder_output, encoder_hidden = encoder(src_sorted_sentence.to(device), src_length_list.to(device))\n",
    "            \n",
    "        decoder_input = torch.tensor([[target_language.word2idx['<SOS>']]] * BATCH_SIZE)\n",
    "        decoder_hidden = encoder_hidden\n",
    "    \n",
    "        for target_length in range(1, tgt_sentence_list.size(1)):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input.to(device), decoder_hidden.to(device))\n",
    "            loss += criterion(decoder_output, tgt_sentence_list[:, target_length].to(device))\n",
    "            decoder_input = tgt_sentence_list[:, target_length].unsqueeze(1)\n",
    "                        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % log_step == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, loss.item()))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
